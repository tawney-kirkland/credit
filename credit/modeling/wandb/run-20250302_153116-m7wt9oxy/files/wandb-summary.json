{"_wandb":{"runtime":44},"AUC":0.8250968476198874,"_timestamp":1.7409475211397948e+09,"_runtime":44.516277,"_step":4,"classification_report":"              precision    recall  f1-score   support\n\n         0.0       0.97      0.82      0.89     23336\n         1.0       0.21      0.67      0.32      1664\n\n    accuracy                           0.81     25000\n   macro avg       0.59      0.74      0.60     25000\nweighted avg       0.92      0.81      0.85     25000\n","confusion_matrix":{"nrows":4,"_type":"table-file","sha256":"9f56ebdfead068d867a7f77b5e018f45bc27717cf20ccf8815f093b4de0d69a5","size":127,"artifact_path":"wandb-client-artifact://s9eqd2gdarpyxejrb5onmjoeuipg4j84axboex56clw4n3bho4awn8nitzo43filw25ihr68wiuxw2y4o872n163mm2bft4zftbqkp7lczia7or9h5iw6dgm5wi4i1vy/confusion_matrix.table.json","_latest_artifact_path":"wandb-client-artifact://kkg4hhjxecemwrcw9d8kndkppgz7m87y4vgetabdswib67d0cjjh0k4or8c0oq8t2lybmhhet1gwa2qzolod4xd0rj7kyetftin5caehyt9xe3u5g2u20hfsjisivld2:latest/confusion_matrix.table.json","path":"media/table/confusion_matrix_4_9f56ebdfead068d867a7.table.json","ncols":3},"cv_accuracy":0.8307400000000001}